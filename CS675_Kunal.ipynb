{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7gwixo601YgN"
      },
      "outputs": [],
      "source": [
        "from fastai.vision.all import *\n",
        "from fastcore.parallel import *\n",
        "import fastai\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from fastai.callback.tracker import SaveModelCallback\n",
        "import timm\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model = timm.create_model(\"efficientformerv2_s2\", pretrained=True)\n",
        "torch.save(model.state_dict(), \"efficientformerv2_s2_weights.pth\")\n",
        "\n",
        "metadata_path = Path(\"/content/drive/MyDrive/CS675-repo/isic_2024_data/train-metadata.csv\")\n",
        "df = pd.read_csv(metadata_path)\n",
        "\n",
        "columns_to_drop = ['copyright_license', 'attribution', 'image_type', 'iddx_1', 'iddx_2', 'iddx_3', 'iddx_4',\n",
        "                   'iddx_5', 'iddx_full', 'mel_mitotic_index', 'mel_thick_mm', 'tbp_tile_type',\n",
        "                   'tbp_lv_dnn_lesion_confidence', 'lesion_id']\n",
        "cat_names = ['sex', 'anatom_site_general', 'tbp_lv_location', 'tbp_lv_location_simple']\n",
        "new_cat_columns = pd.read_csv('/content/drive/MyDrive/CS675-repo/isic_2024_data/new_cat_columns.csv')['new_cat_columns'].tolist()\n",
        "new_cat_columns = [col for col in new_cat_columns if isinstance(col, str) and col in df.columns]\n",
        "cont_names = [x for x in df.columns if x not in (cat_names + ['target', 'isic_id','patient_id'] + columns_to_drop)]\n",
        "y_col = 'target'\n",
        "image_col = 'isic_id'"
      ],
      "metadata": {
        "id": "UmolJzkZ1h97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/MyDrive/CS675-repo/isic_2024_data/train-image/image'\n",
        "\n",
        "df = df[df['isic_id'].apply(lambda x: os.path.exists(os.path.join(image_dir, f\"{x}.jpg\")))].reset_index(drop=True)\n",
        "\n",
        "for col in new_cat_columns:\n",
        "    df[col] = df[col].astype('category').cat.codes\n",
        "\n"
      ],
      "metadata": {
        "id": "LqgCarvW1h53"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "image_dir = '/content/drive/MyDrive/CS675-repo/isic_2024_data/train-image/image'\n",
        "\n",
        "df = df[df['isic_id'].apply(lambda x: os.path.exists(os.path.join(image_dir, f\"{x}.jpg\")))].reset_index(drop=True)\n",
        "\n",
        "df = df.dropna(subset=[y_col]).reset_index(drop=True)\n",
        "\n",
        "for col in new_cat_columns:\n",
        "    df[col] = df[col].astype(str)\n",
        "    df[col] = LabelEncoder().fit_transform(df[col])\n",
        "\n",
        "df[cont_names] = df[cont_names].replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna(subset=cont_names).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "vIrN-uR0j5M4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in new_cat_columns:\n",
        "    df[col] = df[col].astype('category')\n",
        "    if df[col].isnull().any():\n",
        "        df[col] = df[col].cat.add_categories(\"Missing\").fillna(\"Missing\")\n",
        "    df[col] = df[col].cat.codes\n"
      ],
      "metadata": {
        "id": "pBWSptWs4msu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.tabular.model import TabularModel\n",
        "\n",
        "class ImageTabDataset(Dataset):\n",
        "    def __init__(self, df, image_dir, cat_cols, cont_cols, y_col, image_size=224):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.image_dir = image_dir\n",
        "        self.cat_cols = cat_cols\n",
        "        self.cont_cols = cont_cols\n",
        "        self.y_col = y_col\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((image_size, image_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      row = self.df.iloc[idx]\n",
        "      img_path = os.path.join(self.image_dir, f\"{row['isic_id']}.jpg\")\n",
        "      img = Image.open(img_path).convert(\"RGB\")\n",
        "      img = self.transform(img)\n",
        "\n",
        "      x_cat = torch.tensor(row[self.cat_cols].astype('int32').values, dtype=torch.long)\n",
        "      x_cont = torch.tensor(row[self.cont_cols].values.astype('float32'), dtype=torch.float)\n",
        "      y = torch.tensor(row[self.y_col], dtype=torch.long)\n",
        "\n",
        "      return img, x_cat, x_cont, y\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_indices, valid_indices = train_test_split(\n",
        "    df.index,\n",
        "    test_size=0.25,\n",
        "    stratify=df[y_col],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_df = df.iloc[train_indices]\n",
        "valid_df = df.iloc[valid_indices]\n",
        "\n",
        "train_dataset = ImageTabDataset(train_df, image_dir, new_cat_columns, cont_names, y_col)\n",
        "valid_dataset = ImageTabDataset(valid_df, image_dir, new_cat_columns, cont_names, y_col)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
        "dls = DataLoaders(train_loader, valid_loader)\n",
        "\n",
        "def get_emb_szs(df, new_cat_columns):\n",
        "    return [(df[col].nunique() + 1, min(50, (df[col].nunique() + 1) // 2)) for col in new_cat_columns]\n",
        "\n",
        "emb_szs = get_emb_szs(train_df, new_cat_columns)\n",
        "n_cont = len(cont_names)\n",
        "out_sz = len(train_df[y_col].unique())\n",
        "\n",
        "class ImageTabularModel_1(nn.Module):\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
        "        super().__init__()\n",
        "        self.cnn = models.resnet50(weights=True)\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad = False\n",
        "        num_ftrs = self.cnn.fc.in_features\n",
        "        self.cnn.fc = nn.Linear(num_ftrs, out_sz)\n",
        "        for param in self.cnn.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
        "        self.head = nn.Linear(out_sz * 2, out_sz)\n",
        "\n",
        "    def forward(self, x_img, x_cat, x_cont):\n",
        "        if x_cat.dtype != torch.long:\n",
        "            x_cat = x_cat.long()\n",
        "        img_out = self.cnn(x_img)\n",
        "        tab_out = self.tab_net(x_cat, x_cont)\n",
        "        return self.head(torch.cat([img_out, tab_out], dim=1))\n",
        "\n",
        "class ImageTabularModel_2(nn.Module):\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=0.5):\n",
        "        super().__init__()\n",
        "        self.cnn = timm.create_model(\"efficientformerv2_s2\", pretrained=True)\n",
        "        self.fc = nn.Linear(self.cnn.num_features, out_sz)\n",
        "        self.tab_net = TabularModel(emb_szs, n_cont, out_sz, layers, ps)\n",
        "        self.head = nn.Linear(1002, out_sz)\n",
        "\n",
        "    def forward(self, x_img, x_cat, x_cont):\n",
        "        if x_cat.dtype != torch.long:\n",
        "            x_cat = x_cat.long()\n",
        "        img_out = self.cnn(x_img)\n",
        "        tab_out = self.tab_net(x_cat, x_cont)\n",
        "        return self.head(torch.cat([img_out, tab_out], dim=1))\n",
        "\n",
        "model_dir = Path(\"/content/drive/MyDrive/CS675-repo/models\")\n",
        "model_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "loss_func = CrossEntropyLossFlat()\n",
        "\n",
        "model_1 = ImageTabularModel_1(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
        "model_2 = ImageTabularModel_2(emb_szs, n_cont, out_sz, layers=[512, 256, 128], ps=0.5).to(device)\n",
        "\n",
        "model_1 = torch.nn.DataParallel(model_1)\n",
        "model_2 = torch.nn.DataParallel(model_2)\n",
        "\n",
        "from fastai.callback.tracker import SaveModelCallback\n",
        "\n",
        "from fastai.callback.core import Callback\n",
        "\n",
        "class SaveEachEpochCallback(Callback):\n",
        "    def after_epoch(self):\n",
        "        epoch = self.epoch\n",
        "        filename = f\"epoch_{epoch}_model1\"\n",
        "        self.learn.save(filename)\n",
        "        print(f\"âœ… Saved model: {filename}.pth\")\n",
        "\n",
        "\n",
        "learn_1 = Learner(\n",
        "    dls,\n",
        "    model_1,\n",
        "    loss_func=loss_func,\n",
        "    opt_func=partial(Adam, lr=0.001),\n",
        "    metrics=accuracy,\n",
        "    cbs=[\n",
        "        SaveEachEpochCallback(),\n",
        "        SaveModelCallback(monitor='valid_loss')\n",
        "    ],\n",
        "    wd=1e-3,\n",
        "    model_dir=Path(\"/content/drive/MyDrive/CS675-repo/models\")\n",
        ")\n",
        "\n",
        "\n",
        "learn_2 = Learner(\n",
        "    dls, model_2, loss_func=loss_func, opt_func=partial(Adam, lr=0.001),\n",
        "    metrics=accuracy,\n",
        "    cbs=SaveModelCallback(monitor='valid_loss', fname='best_model_2'),\n",
        "    wd=1e-3,\n",
        "    model_dir=model_dir\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m4ILePiE1h2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_lr = 0.005\n",
        "learn_1.save('model')\n",
        "learn_1.fine_tune(5)\n",
        "#learn_2.fine_tune(5)"
      ],
      "metadata": {
        "id": "yNAc0QRc1hy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_2.save('model1')\n",
        "#learn_1.fine_tune(5)\n",
        "learn_2.fine_tune(5)"
      ],
      "metadata": {
        "id": "3Hya4-u-1hu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_columns = df.columns.tolist()\n",
        "train_columns.remove('target')\n",
        "\n",
        "df_test, _ = process_data(df_test, cat_names)\n",
        "\n",
        "for col in train_columns:\n",
        "    if col not in df_test.columns:\n",
        "        df_test[col] = 0\n",
        "\n",
        "df_test = df_test[train_columns]\n"
      ],
      "metadata": {
        "id": "9xFtNXWN5cQJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "import h5py\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def process_data(df, cat_names):\n",
        "    df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
        "    df['numb_pic'] = df.groupby('patient_id')['patient_id'].transform('count')\n",
        "\n",
        "    if 'age_approx' in df.columns:\n",
        "        df['age_approx'] = df['age_approx'].fillna(df['age_approx'].mode()[0])\n",
        "    if 'sex' in df.columns:\n",
        "        df['sex'] = df['sex'].fillna(df['sex'].mode()[0])\n",
        "\n",
        "    df = pd.get_dummies(df, columns=cat_names, prefix=cat_names)\n",
        "    new_cat_columns = [col for col in df.columns if any(col.startswith(name + '_') for name in cat_names)]\n",
        "    return df, new_cat_columns\n",
        "\n",
        "ROOT_DIR = \"/content/drive/MyDrive/CS675-repo/isic_2024_data/\"\n",
        "TEST_HDF = f'{ROOT_DIR}/test-image.hdf5'\n",
        "TEST_CSV = f'{ROOT_DIR}/test-metadata.csv'\n",
        "\n",
        "df_test = pd.read_csv(TEST_CSV)\n",
        "df_test, _ = process_data(df_test, cat_names)\n",
        "\n",
        "for col in new_cat_columns:\n",
        "    if col not in df_test:\n",
        "        df_test[col] = 0\n",
        "df_test = df_test[[c for c in df.columns if c != 'target']]"
      ],
      "metadata": {
        "id": "LmyOh0OO1hqq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedDataset_test(Dataset):\n",
        "    def __init__(self, df, file_hdf, cat_names, cont_names, transforms=None, target_size=(224, 224)):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
        "        self.isic_ids = df['isic_id'].values\n",
        "        self.cat_names = cat_names\n",
        "        self.cont_names = cont_names\n",
        "        self.transforms = transforms\n",
        "        self.target_size = target_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        isic_id = self.isic_ids[index]\n",
        "        img = Image.open(BytesIO(self.fp_hdf[isic_id][()])).convert('RGB')\n",
        "        img = img.resize(self.target_size)\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        row = self.df.iloc[index]\n",
        "        x_cat = torch.tensor(row[self.cat_names].astype('int32').values, dtype=torch.long)\n",
        "        x_cont = torch.tensor(row[self.cont_names].astype('float32').values, dtype=torch.float)\n",
        "        dummy_y = torch.tensor(0, dtype=torch.long)\n",
        "        return img, x_cat, x_cont, dummy_y\n",
        "\n",
        "data_transforms = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "test_dataset = CombinedDataset_test(df_test, TEST_HDF, new_cat_columns, cont_names, transforms=data_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=4, shuffle=False)\n",
        "\n",
        "learn_1.model.eval()\n",
        "learn_2.model.eval()\n",
        "\n",
        "def get_model_predictions(learn, test_loader):\n",
        "    with torch.no_grad():\n",
        "        logits, _ = learn.get_preds(dl=test_loader)\n",
        "        return F.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "probs_1 = get_model_predictions(learn_1, test_loader)\n",
        "probs_2 = get_model_predictions(learn_2, test_loader)\n",
        "\n",
        "avg_probs = (probs_1 + probs_2) / 2\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    \"isic_id\": test_dataset.isic_ids,\n",
        "    \"target\": avg_probs\n",
        "})\n",
        "\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "submission_df.head()\n"
      ],
      "metadata": {
        "id": "ZWjUz15u1hmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o43ECnXl1hh7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}